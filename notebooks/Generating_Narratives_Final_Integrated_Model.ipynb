{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9WfYHhbjGrw"
      },
      "source": [
        "RUN the below mention codes and stall the packages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-4rF9E-LpWr"
      },
      "outputs": [],
      "source": [
        "!pip install gTTS #Run This First"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jeyW3M7P3ec"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade transformers #Run This Second"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDfHit_nMasZ"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio transformers diffusers #Run This Third"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OamwWHZiXqR"
      },
      "source": [
        "After installing all the above pakages mentioned. Proceed with login by entering Hugging Face Login Token.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "spW91FO9QKoV"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\") #Enter Your API KEY or LOGIN TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNBQ0E59iwVa"
      },
      "source": [
        "After entering your token key run the code and proceed to next part for main story generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9fQ8zmVM8q5"
      },
      "outputs": [],
      "source": [
        "#Important packages\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from gtts import gTTS\n",
        "\n",
        "# Function to generate an image based on a textual prompt using Stable Diffusion\n",
        "def generate_image(prompt):\n",
        "  # Load the Stable Diffusion model (v1.4) for image generation\n",
        "    model_id = \"CompVis/stable-diffusion-v1-4\"\n",
        "    pipen = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "    pipen = pipen.to(\"cuda\") # Move the model to the GPU for faster inference\n",
        "    # Generate the image based on the prompt\n",
        "    image = pipen(prompt,guidance_scale=7.5).images[0]\n",
        "    return image\n",
        "\n",
        "# Load the PHI-3 model for story generation\n",
        "torch.random.manual_seed(0)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")\n",
        "\n",
        "# Prompt for the PHI-3 model to generate a counter-narrative story\n",
        "prompt=\"\"\"<|system|>\n",
        "You are a persuasive and factually accurate story-generating assistant with a journalistic rigor.\n",
        "<|end|>\n",
        "<|user|>\n",
        "Given a claim and corresponding facts, generate a summarized well-structured story that meets the following criteria:\n",
        "\n",
        "- Refute the claim using every provided fact, along with additional context from historically accurate trends and statistics.\n",
        "- Limit the response to a maximum of 250 words.\n",
        "- Use a strongly critical tone, directly highlighting the flaws in the claim and emphasizing its misleading nature.\n",
        "- Include relevant background information, citing historically significant economic events or definitions (e.g., major inflation periods or economic milestones\n",
        "- When writing about public figures, always use their correct title based on their current or former status:\n",
        "     Example: Use “former President” for Donald Trump, who no longer holds office, and “President” for Joe Biden, who is currently in office.\n",
        "     Similarly, for any retired officials, use titles like “former” or “ex-” as appropriate.\n",
        "- The narrative-based summarized story should be coherent and persuasive, leaving no room for doubt about the validity of the refutation.\n",
        "- The summarized story must follow a clear 3-paragraph structure:\n",
        "\n",
        "  Paragraph1- Begin with historical background or context around the event or term in question.\n",
        "  Paragraph2- Progress to opposing the claim in a detailed manner, referencing the provided facts and relevant historical events to refute it.\n",
        "  Paragraph3- Conclude with a strong, fact-based analysis that highlights the flaws in the claim and clarifies the reality of inflation trends.\n",
        "\n",
        "Claim:Trump claimed that before he signed a “Right to Try” law in 2018 to give terminally ill patients easier access to experimental medications that haven’t yet received approval from the Food and Drug Administration, such patients would have no recourse if they did not have the money to travel abroad.\n",
        "\n",
        "He said: “You know, people – if they had money, they’d go to Asia, they’d go to Europe. If they don’t have money, they’d go home and die. That’s what happened, they’d go home and die.”\n",
        "\n",
        "Facts: It is not true that terminally ill patients would simply have to go home and die without any access to experimental medications or would have to go to foreign countries seeking such treatments until Trump signed the Right to Try law. Prior to the law, patients had to ask the federal government for permission to access experimental medications – but the government almost always said yes.\n",
        "\n",
        "Scott Gottlieb, who served as Trump’s FDA commissioner, told Congress in 2017 that the FDA had approved 99% of patient requests under its own “expanded access” program.\n",
        "\n",
        "“Emergency requests for individual patients are usually granted immediately over the phone and non-emergency requests are generally processed within a few days,” Gottlieb testified.\n",
        "\n",
        "<|end|>\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "# Set up a pipeline for text generation using the PHI-3 model\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "# Define arguments for the text generation task\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 2000,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.7,\n",
        "    \"do_sample\": False,\n",
        "}\n",
        "# Generate the story based on the input prompt\n",
        "output = pipe(prompt, **generation_args)\n",
        "story=output[0]['generated_text']\n",
        "\n",
        "# Load the Llama 3.2 model for generating a visual concept for the story\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipes = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Define the message for Llama 3.2 to transform the story into a visual concept\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Convert complex narrative into a single, powerful visual metaphor for image generation.Ensure the description avoids using text, numbers, or written symbols in the imagery.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Transform this story into a precise, single-line image concept:\n",
        "\n",
        "Story Key Elements:\n",
        "- use graphs or tug-of-war to show contrast between actual claimed trends where needed\n",
        "\n",
        "Story Context: {story}\n",
        "\n",
        "Generate a concise, symbolic visual representation in one line.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "# Generate the image prompt from the story\n",
        "outputs = pipes(\n",
        "    messages,\n",
        "    max_new_tokens=77,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "# Extract the generated visual concept\n",
        "img=outputs[0][\"generated_text\"]\n",
        "# Use Stable Diffusion to generate an image based on the visual concept\n",
        "generate_image(img)\n",
        "# Print the generated story for reference\n",
        "print(story)\n",
        "\n",
        "# Generate audio for the story using Google Text-to-Speech (gTTS)\n",
        "tts = gTTS(story, lang='en')\n",
        "tts.save(\"output.mp3\") # Save the generated audio to an MP3 file\n",
        "\n",
        "# Play the generated audio file\n",
        "from IPython.display import Audio\n",
        "Audio(\"output.mp3\", autoplay=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
