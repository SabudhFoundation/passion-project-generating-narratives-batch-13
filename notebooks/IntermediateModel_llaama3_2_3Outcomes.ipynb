{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **for generating instructions from counter-narrative directly**"
      ],
      "metadata": {
        "id": "TCljwpMfgcgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a34f19be-a80e-4a5d-fb3c-395d917a8b3f",
        "id": "bZBfxRuWuzk6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.47.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")\n"
      ],
      "metadata": {
        "id": "JFIuV-hIIX9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"In the midst of economic turmoil, former President Donald Trump's declaration that the United States was experiencing the \"worst inflation we've had in 100 years\" has sparked controversy and skepticism. This claim, made in the context of the Biden administration's economic policies, has been widely debunked by economic experts and historical data.\n",
        "\n",
        "Firstly, Trump's assertion that the current inflation rate was unprecedented in the last century is factually incorrect. The highest inflation rate recorded in the United States since the establishment of the Federal Reserve in 1913 was 20.1% in 1946, during the post-World War II era. The inflation rate peaked at 9.1% in June 2022, which, while significant, was not a record-breaking figure. This peak occurred 41 years after the previous high, not the 100 years Trump suggested. Furthermore, the most recent inflation rate at the time of Trump's statement, for July 2024, was 3.2%, a rate that was not only lower than the peak but also surpassed rates seen in 2011.\n",
        "\n",
        "The flaws in Trump's claim are evident when examining the historical context and current economic data. His statement not only misrepresents the severity of the inflation experienced during his presidency but also overlooks the natural fluctuations in economic indicators over time. The reality is that while the Biden presidency has faced its own economic challenges, the inflation rate has shown a significant decline from its peak in June 2022. This decline underscores the dynamic nature of the economy and the importance of accurate, data-driven analysis in understanding and addressing inflationary trends. Trump's statement, therefore, not only lacks factual accuracy but also fails to provide a nuanced understanding of the economic landscape. \"\"\"\n",
        "\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Convert complex narrative into a single, powerful visual metaphor for image generation.Ensure the description avoids using text, numbers, or written symbols in the imagery.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Transform this story into a precise, single-line image concept:\n",
        "\n",
        "Story Key Elements:\n",
        "- use graphs or tug-of-war to show contrast between actual claimed trends where needed\n",
        "\n",
        "Story Context: {story}\n",
        "\n",
        "Generate a concise, symbolic visual representation in one line.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=77,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583,
          "referenced_widgets": [
            "e83989f9ae254b1c8c38d5a58ceecf9a",
            "287ae895fb0e4c4687576a7cdaee6607",
            "30edb559839a494f819fd0c1578c58a2",
            "9a949ede688e444585312dbc757c8f68",
            "166c74e99ade484ead2aca5c579644c7",
            "206b2a7c04504ba785cb7507f71d11c9",
            "2efe8bde8b9b4306afa20452cd5f6e4e",
            "8d6ce93d6d6e4136b662713a63a9c1d1",
            "7a3152f6e9de4f7bb6882a936a83ca9c",
            "a1648ee5469c404da9d9c036ad252c43",
            "55a9a9cd44c84b76b7d17e3b4f230cc2",
            "30cf0755af554850a016ff299e2c5045",
            "43e5c370460949999c71d7ef2459aa54",
            "7752d52f98784380b866945143f46bdd",
            "aa56a751cfe44e9d80bc340df1f2a7e6",
            "4ca2131d9b2e414ea437529562be3283",
            "48fa802c91d84df299690298816a0b5d",
            "2784d5a519ba4f6e93f3fc556be7dd42",
            "18306b67d1a9487dbef88a68cdba7298",
            "6a8f034dfa46498c824e6f722fc38dbd",
            "b8a4f43b31e447c09b39eb542b972886",
            "c0c9daf243a54a21ba858fd7cee604a7",
            "39ebeff488fe4c72b885fee39c632a98",
            "d987b602a74747baaf29bd589a6f3bcb",
            "87d5f4d5d98d4ba780f131ec6d9163dd",
            "5304d278487249dd9b339934f09bef3c",
            "2f775f163fdf416fa68c4909d37296a0",
            "52f9ed4cb42040a2bf735c2450092b8d",
            "9d9252b3c40b465194edb3749012a0df",
            "76184d815f3046b8ab9a9a624b227f67",
            "86844c63f0334ce6b1a99e8e1b612625",
            "50f67e5578634a568f9a196231130928",
            "96d66afd330541d785a76280dea2aaa8",
            "4685209ea45c4a6eae3592f48f49baee",
            "f76a7d6569a04376b1e94d9d9042db09",
            "feb9b44e7faf402eb7d6898675625bab",
            "117f96b4ccef42f5bd6513067e12a3ee",
            "b6dd44567ab6489a894ee74d42b67690",
            "82e8d09b895e4e21a7d278e1eb74bf0b",
            "d7669ce88fec49bb8dafdf2b57ab58b0",
            "de822293f8b6482bad2ab62bf8543e57",
            "dd2ef99bd8324f72b99994871a734f45",
            "16c7099bce4943d2acdeab28bb0492ee",
            "cb39d4ed798b4722aae9ddd94ee734a0",
            "3bb9a5eae0a74dcd847764850f45d2f5",
            "d1ecd6cbf90246298ff54e48d10a4750",
            "24c2572e67e348cca7820674b7654ce3",
            "baa4f8188fbf4baab4e4fccd645457ec",
            "1f742f8eb6534360a7b8093449ff7ae5",
            "ffc542421a524b8cb34582fe629de15d",
            "48e32a43d2064353a7161f3dae2e8305",
            "264e5be23f9c495d8f2eaac5dfd9c1b3",
            "e885ecb9a455476b93a294891b851216",
            "1caadae8575a4fd99024da417ab495bb",
            "617f0e0245d649b2910c912c0ea47c74",
            "441ccfd5c60e4df2ab8aed8877bf9ef1",
            "f3065ee0a98a4005a8d3b6dabdacd3e2",
            "7cab2e0815bc4770b9a486bc10425251",
            "0e09a2f2d49f41068d62767b9576edfa",
            "5f5750c50b0041398e232540f8c30596",
            "fde6f835422144298e3cc98da4cd4fe9",
            "0f1bd1b16a1340efb915003c1a763871",
            "2dfebf3c963c4348acfb12785d20041a",
            "69a8b6f7972c479697216b5c018aa111",
            "abe9227dee654658aed85579c08c2a65",
            "9e6d1cb96646438d904a041cc03b841b",
            "4e30c14a4f3a43aba5462c41424d7775",
            "6da3d1da65f44200a5558fefa832a0f8",
            "110823e3a7df44cc807356d4ef4cc722",
            "8c0a0ae0cd90467da5f03ced7b123322",
            "6d83a41dc8074d65b172e7b34d507aac",
            "e7eb0085a41c49809bc02f89225e5b3d",
            "ee14c7b918a14bb4919419d03bd3e4f9",
            "77e9128a85ce4aabaaedf0d9baae7b58",
            "cbe063b61d6349b29565d7c5ca41f58a",
            "2628c4794fd445a09d72282932f8198b",
            "5340960559424b59a9e714f855f9b0ca",
            "b0d0789cd7204b61a9c6010c3b9c217d",
            "af838d944a0d4b868c3c14f0a1916388",
            "ac3d51e6c81046a686e87f48f4cd5316",
            "f7790c97acdf499aaae7f3d79ee27a40",
            "571f4e41de01419bbf577a6171fcd816",
            "2a6a31ceb9af474da55caee8dc0310fc",
            "541f10f13a104be399e9b602c8cbfbfd",
            "614072e8cb974f32bc3bf7d68167c5f8",
            "eb2e4addf0bb4284b0580d5bfc4754ac",
            "d103ad46c8c54aecba2e5e27902e1dc7",
            "b4904562b0e04bf68782252c5e170b59",
            "3087839a67c44c0e9a7c1dd52ccf6259",
            "16f9affaee3b4270b064e62c8d4bc83b",
            "fe69ecb9ebfc4483b6ce84c9d6245a76",
            "4b0cf17487b84671acefec8344de41d6",
            "3743fcd52cf0499d9faec0ac333d789d",
            "8c8f41eaefe544c3b3a5ec35ec2cfcc5",
            "82417109589c4adb9508d78c5738c0b4",
            "cca3b891bd714d499ce2549ec44d926d",
            "394009a23cb847328c451eb74e124927",
            "24939f223ad846a0a4e3f75e01771c1c",
            "4f7482b3a23e4e6e98fabe359f6a66f1",
            "7415b55ba95445238e3c71644f328bb4",
            "7966790c120f41c29070cc72969099f5",
            "a8974aa15a6b4eab88362c5e6e825633",
            "b7d9d6549d584c48a42670699d7843ab",
            "33610ee4dee54aee8ded6d6e55290233",
            "2e0bb70fa01845f7ac438b637378bef5",
            "17634435f3c54c2d9db610b55e6c9d37",
            "f1660b6e0cb548f59bdea4e07b5e3166",
            "17c539f916764d3b89152479ef9b9c60",
            "2bc6332eb102409eb0e66f19282ca24a",
            "b233d3654a824a4ba09c26ef47becea4"
          ]
        },
        "outputId": "a41c53e3-074e-441a-c56e-ccdc7e734e8b",
        "id": "K0qXWD5WuD_t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e83989f9ae254b1c8c38d5a58ceecf9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30cf0755af554850a016ff299e2c5045"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39ebeff488fe4c72b885fee39c632a98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4685209ea45c4a6eae3592f48f49baee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bb9a5eae0a74dcd847764850f45d2f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "441ccfd5c60e4df2ab8aed8877bf9ef1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e30c14a4f3a43aba5462c41424d7775"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0d0789cd7204b61a9c6010c3b9c217d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3087839a67c44c0e9a7c1dd52ccf6259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7415b55ba95445238e3c71644f328bb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A tug-of-war rope with a frayed end, representing the false claim, is pulled by a figure in a suit, symbolizing Trump, while a figure in a suit with a rope of smooth, unbroken thread, representing accurate data, pulls in the opposite direction, signifying the truth and the decline in inflation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "\n",
        "# Define the story variable here, before it's used in the messages list\n",
        "story=\"\"\"In the wake of President Trump's controversial remarks about the US military's financial contributions to Afghanistan, it's crucial to dissect the historical context and facts surrounding the US-Afghan military relationship. Since 2005, the US has invested approximately $18.6 billion in military equipment for Afghan forces, a figure that Trump misleadingly inflated to $85 billion. This misrepresentation overlooks the Defense Department's estimate that the abandoned equipment was worth only about $7.1 billion.\n",
        "\n",
        "President Trump's claim not only distorts the actual financial commitment but also misrepresents the condition of the equipment left behind. While it's true that some equipment was rendered inoperable before the US withdrawal, the majority of the equipment provided was valuable and operational. The $83 billion figure Trump cited is closer to the total amount Congress appropriated for the Afghan security forces fund, not a direct transfer of military equipment value. This figure includes a minor portion for equipment, further discrediting the claim of a massive $85 billion \"gift\" to the Taliban.\n",
        "\n",
        "The flawed narrative presented by President Trump undermines the complexity of the US-Afghan military relationship and the economic realities of war funding. By inflating the value of the equipment left behind and misrepresenting the total funding, Trump's statement fails to acknowledge the significant investment made by the US in supporting Afghan forces. The reality is that the US provided substantial military aid, but the claim of an $85 billion \"gift\" to the Taliban is a gross exaggeration that misleads the public and oversimplifies the nuanced economic and military dynamics of the conflict.\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Convert complex narrative into a single, powerful visual metaphor for image generation.Ensure the description avoids using text, numbers, or written symbols in the imagery.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Transform this story into a precise, single-line image concept:\n",
        "\n",
        "Story Key Elements:\n",
        "- use graphs or tug-of-war to show contrast between actual claimed trends where needed\n",
        "\n",
        "Story Context: {story}\n",
        "\n",
        "Generate a concise, symbolic visual representation in one line.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=77,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "125423a67f1c4ae085f16d727c4c7dec",
            "c10a2ed5fb0d4d12ad4d51124df8baec",
            "7ddf06e53d724d3781fc3de049b2cd2d",
            "759731b53c8f42b2bb0119c5bc96bd1c",
            "234a602bb1fc4226ae8eaae86fd4afbb",
            "919327f0f0cf411baafa6f3f10290fbe",
            "693c6c5dc9814d7faea32f2e02c3f99b",
            "670c62da966b4661aa66e4201e85d0fa",
            "933f31bf277a4fff9fc3c92d786a20d8",
            "20f8f8c22b4447f28ab2ab189c784cf7",
            "d800f0e7fe954daf9325e5a541dccf4c"
          ]
        },
        "id": "Ccr6z1qV2eLg",
        "outputId": "d74560ed-f676-4eae-a8cd-e32ec402e952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "125423a67f1c4ae085f16d727c4c7dec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A tug-of-war rope with one end labeled \"$85 billion\" and the other end labeled \"$7.1 billion\" with a tangled mess of broken and operational equipment in the middle, symbolizing the distorted narrative and the complexity of the US-Afghan military relationship.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X40Rs1wH2-Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "\n",
        "# Define the story variable here, before it's used in the messages list\n",
        "story=\"\"\" The discourse surrounding the urgency of global threats has often been polarized, with former President Trump prioritizing the specter of nuclear conflict over the existential crisis of climate change. However, this stance is not only misinformed but dangerously dismissive of the scientific consensus and the immediate reality of climate change impacts.\n",
        "\n",
        "\n",
        "Contrary to Trump's assertion that the ocean's rise over the next 400 years would be negligible, NASA's data reveals a starkly different picture. The global average sea level has been rising at a rate of 0.17 inches per year in 2023, a figure that is more than double the rate Trump suggested. This acceleration is not a distant future concern but a present-day crisis, with the rate of rise between 2014 and 2023 being about 0.19 inches per year. The misleading claim that sea levels would only rise by an eighth of an inch over 400 years grossly underestimates the current pace and trajectory of sea-level rise.\n",
        "\n",
        "\n",
        "The implications of this accelerated sea-level rise are profound and far-reaching. Coastal regions, including Trump's home state of Florida, are expected to experience disproportionate effects, with rising seas threatening to inundate homes, displace communities, and devastate ecosystems. The notion that rising seas could create more oceanfront property is a dangerous fallacy that overlooks the catastrophic consequences for human settlements and natural habitats. The reality is that climate change poses an immediate and escalating threat to global security, economic stability, and the very survival of countless species, including our own. Trump's misrepresentation of the facts not only undermines informed public discourse but also hinders the urgent action required to address this global emergency.\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Convert complex narrative into a single, powerful visual metaphor for image generation.Ensure the description avoids using text, numbers, or written symbols in the imagery.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Transform this story into a precise, single-line image concept:\n",
        "\n",
        "Story Key Elements:\n",
        "- use graphs or tug-of-war to show contrast between actual claimed trends where needed\n",
        "\n",
        "Story Context: {story}\n",
        "\n",
        "Generate a concise, symbolic visual representation in one line.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=77,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "a0aafac2a2e34979843a28e0b6ddcd57",
            "5c15cd9238574e98b6e2fc6ff5509a66",
            "51e844335d844f2b812ede785c474ac2",
            "254f3237ee1848238afcce704e04a415",
            "477ba0e5784f421cab8cfb6e7b05aeca",
            "5a95d26c882543188e8ad0c9083cf9ad",
            "8a733558167745dab19d25003da2c256",
            "24eafd9216bf49d3a3962f6ab5ebd6c7",
            "24a19567e2464d82b04f6fa07069f09c",
            "6e6c8dbc4f70458185d15d1d8d107bd6",
            "ea06aacd5b424aaf87c43b9784390aef"
          ]
        },
        "outputId": "a8e3818c-7242-4e97-986e-0e2f8dd1afac",
        "id": "r4S6DdYX3BlW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0aafac2a2e34979843a28e0b6ddcd57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A tug-of-war rope with a massive, rapidly rising tide pulling one end, while a small, slow-moving rope representing Trump's claim is being pulled back by a figure in the distance, symbolizing the urgent need for action against climate change.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "\n",
        "# Define the story variable here, before it's used in the messages list\n",
        "story=\"\"\"   In the midst of a heated exchange between former President Donald Trump and Tesla CEO Elon Musk, Trump made a bold claim that Musk's words were being heard by an audience of \"like 60 million or something.\" This statement, made during a publicly televised event, has since been scrutinized for its accuracy.\n",
        "\n",
        "Contrary to Trump's assertion, the actual number of accounts listening to the conversation was a mere 1.1 million, as per public data on the platform where the discussion took place. Trump's figure was not only inflated but also misleading, as it conflated the number of viewers of his own post with the number of people who actively listened to the conversation. The majority of the post's viewers were likely passive observers, not engaged participants in the dialogue.\n",
        "\n",
        "The claim made by Trump not only misrepresents the scale of the audience but also undermines the credibility of his statements. It is essential to recognize that such exaggerations do not reflect the reality of the situation. Historical economic trends, such as the Great Inflation of the 1970s, demonstrate the importance of accurate data in understanding economic phenomena. Inflation, defined as the rate at which the general level of prices for goods and services is rising, and subsequently, purchasing power is falling, requires precise measurement and analysis. Trump's inflated claim about the audience size is akin to misrepresenting economic data, which can lead to misguided policies and public misperception. It is crucial to rely on factual information to make informed decisions and understand the true scope of economic and social issues.\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Convert complex narrative into a single, powerful visual metaphor for image generation.Ensure the description avoids using text, numbers, or written symbols in the imagery.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Transform this story into a precise, single-line image concept:\n",
        "\n",
        "Story Key Elements:\n",
        "- use graphs or tug-of-war to show contrast between actual claimed trends where needed\n",
        "\n",
        "Story Context: {story}\n",
        "\n",
        "Generate a concise, symbolic visual representation in one line.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=77,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "2825e6cc1dd84c46aa0b0234981e4ef1",
            "983598e07ead41bbab609806766939fc",
            "e6a6e69f5a424261b9c8dcf9f5dfae49",
            "f8423dbb667b4cbb8d02543a3228b28b",
            "709c40a34ab84031aa900f2fbde616d9",
            "a20c668c819547d993c0ca988e96d488",
            "a7d0356915a8444d8bf9fa384b45a93f",
            "4d8fa33897fd427cae98eb9643326f7c",
            "14d3178c9d4e4a57a28cd9fc83068425",
            "0911fc7fd1e940f68b8dfdf51b030351",
            "8716dab34a1745f4a72df096d12b7a4f"
          ]
        },
        "id": "iFrDzhVl4p7X",
        "outputId": "942c4768-a57d-4697-cc4b-e9df54b1dfe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2825e6cc1dd84c46aa0b0234981e4ef1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A tug-of-war rope with 1.1 million tiny, struggling threads on one side and a massive, inflated rope with 60 million threads on the other, symbolizing the stark contrast between Trump's exaggerated claim and the actual audience size.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "\n",
        "# Define the story variable here, before it's used in the messages list\n",
        "story=\"\"\"   In the context of international relations and economic sanctions, the claim by former President Donald Trump that he compelled China to cease purchasing oil from Iran is a misleading assertion. During his presidency, the Trump administration indeed sought to curtail Iran's oil exports, a significant source of revenue for the Islamic Republic. In 2019, the administration's efforts led to a temporary decline in China's oil imports from Iran, which fell from around 800,000 barrels per day in 2018 to approximately 100,000 barrels per day by late 2019. However, this reduction was not sustained, and imports rebounded to levels between 600,000 and 700,000 barrels per day by the time Trump left office in January 2021.\n",
        "\n",
        "\n",
        "The claim that China ceased its oil purchases from Iran under Trump's leadership is factually incorrect. Industry experts, including Matt Smith from Kpler, have noted that China's reported crude imports from Iran in January 2021 were zero, but this does not reflect the reality of ongoing trade. China has been known to employ various methods to obscure its oil purchases, such as listing Iranian crude as originating from Malaysia or transferring oil to other vessels once near Malaysian waters. These tactics have allowed China to continue its oil imports from Iran despite international sanctions.\n",
        "\n",
        "\n",
        "The narrative that Trump single-handedly pressured China to stop buying Iranian oil is not only false but also overlooks the complexities of international trade and the resilience of global supply chains. The International Crisis Group's report by Ali Vaez confirms that China's oil imports from Iran increased significantly after the Trump administration's efforts. This refutation underscores the fallacy of Trump's claim and highlights the importance of understanding the nuanced dynamics of global oil markets and the limitations of unilateral sanctions in altering long-standing trade relationships.\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Convert complex narrative into a single, powerful visual metaphor for image generation.Ensure the description avoids using text, numbers, or written symbols in the imagery.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Transform this story into a precise, single-line image concept:\n",
        "\n",
        "Story Key Elements:\n",
        "- use graphs or tug-of-war to show contrast between actual claimed trends where needed\n",
        "\n",
        "Story Context: {story}\n",
        "\n",
        "Generate a concise, symbolic visual representation in one line.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=77,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "0c43cb6b2d704cbf812d356d34be2a43",
            "1d19691a11bd40b09241c319bbf4e16b",
            "6486bbdb785449f69355da32451dd944",
            "95fb836447ac45ea950c4fe2daf57214",
            "de170c941c244a8f9e1496b914b4d40a",
            "e92399d6d4ee427a8a5f351066984821",
            "eb04e912e1014a1abd79d27f2206d1b5",
            "55b4cba3b0f446f188c7778bfa3b32fd",
            "becdbb9aeb8d44a6ae6b9c1f9119d2f3",
            "fed709fd401d4c79abf64bd01d607032",
            "c08155c2f856449db4a98cfdce22fcdb"
          ]
        },
        "id": "uoxrLLVl5p_8",
        "outputId": "cd8361d3-0c2c-4f84-81b6-7c1d4edd162f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c43cb6b2d704cbf812d356d34be2a43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A tug-of-war rope with a small, almost imperceptible tug on one end, while the other end is being pulled by a figure in the distance, with a rope of oil flowing freely from the other end, symbolizing the subtle yet persistent influence of global forces on international trade.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "\n",
        "# Define the story variable here, before it's used in the messages list\n",
        "story=\"\"\"counter narrative\n",
        "In the tumultuous arena of American politics, claims of election subversion have periodically surfaced, often casting long shadows over the democratic process. The former President, Donald Trump, has been a vocal proponent of such narratives, alleging that the Biden administration orchestrated legal actions against him in various jurisdictions. These claims, however, are not only baseless but also detrimental to the integrity of the electoral system.\n",
        "\n",
        "The Manhattan case, where Trump was found guilty, is a prime example of the fallacy in Trump's assertions. Attorney General Merrick Garland's testimony to Congress clarified that the Manhattan district attorney operates independently of the federal government, including the Justice Department. This autonomy is a cornerstone of the American legal system, ensuring that local jurisdictions can enforce state laws without federal interference. Furthermore, Matthew Colangelo, the lawyer Trump repeatedly cited, was not appointed by the Biden administration but was a colleague from the New York attorney general's office before joining Bragg's office. This fact alone dismantles the notion of a coordinated effort by the Biden administration to target Trump.\n",
        "\n",
        "The reality of inflation trends and economic milestones further underscores the misleading nature of Trump's claims. Inflation, a complex economic phenomenon influenced by a myriad of factors including monetary policy, supply chain disruptions, and global events, cannot be attributed to a single administration's actions. Historical data shows that inflation rates have fluctuated over the decades, with significant periods of both high and low inflation. The current inflationary trends are a result of a confluence of global economic challenges, not the machinations of any one political entity. Trump's unfounded allegations not only misrepresent the facts but also undermine the public's understanding of economic realities. The evidence clearly refutes the claim that the Biden administration orchestrated legal actions against Trump, highlighting the importance of basing political discourse on facts rather than unfounded accusations.\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Convert complex narrative into a single, powerful visual metaphor for image generation.Ensure the description avoids using text, numbers, or written symbols in the imagery.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Transform this story into a precise, single-line image concept:\n",
        "\n",
        "Story Key Elements:\n",
        "- use graphs or tug-of-war to show contrast between actual claimed trends where needed\n",
        "\n",
        "Story Context: {story}\n",
        "\n",
        "Generate a concise, symbolic visual representation in one line.\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=77,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583,
          "referenced_widgets": [
            "25d6068746114c69878ae62dd7e85ed1",
            "631444fd7d1642cdb75163259546f244",
            "c5d03976fbd546e9b3a1141a84c9a371",
            "97f8f4a236d9454e8810b583d02c9817",
            "668122826af44182a08265eb2da71cd6",
            "359d63f1477149a2bb14ff6931ed7687",
            "1ef01f097363405483c644b00bf6fc90",
            "bc3ffb8b2fe0473c80f17f3f2e5c73f8",
            "10fd86c51b144fb69a2f399bbe2e9ea8",
            "d0baf4372bc244b0856f16fce2bd4548",
            "ba8b4a30a9134a4083eb5f49b2a2622b",
            "910c623d0cf54474a78d30ad4a1b2072",
            "633546f9c834438f94c31a6f2241043e",
            "2aa57e0da26d4b62883edf7fa58a169e",
            "b6085a56632b4abd8a279d2c3e6b9a53",
            "f4c9d2ba4df0493a913f0358947c4d5d",
            "ae3f128c9f59458e97758d97cc21f1fb",
            "711d03606232476c86799f339a15f81c",
            "51cc38464d564a2dba666b6f280d096e",
            "fbffe74b169049199d6f1718238b998e",
            "f4d84c4988e847b283753b2a42728002",
            "a5849dc9d5de4d128d46ed1d678991f7",
            "3e009d886b1b44f88139512e8c5e4f75",
            "5f53c5e7b9e148cfb88d8173ff9b0a9c",
            "53d3a3de0e4c45dbb1794441ec839986",
            "e90aa794e7144ac69382f53082b719a3",
            "01784c8173be4d0aba281fecef18016c",
            "5aae34ffcdda4a868cc5ad1ffdbfa2e1",
            "0f8935567536407e8f47451ae16f290a",
            "436be6cdf987402293953866f297b342",
            "e84950d9a03c4837b0151f95ac708c02",
            "ec9157dcd4d645b5a5cc64ef1b1a4494",
            "e460a6d14a95410d90782564f4b678e2",
            "c426b9c027364a48b02085d3186e444f",
            "8f79726a7b844459893eefd1d2b3a77c",
            "5c4bb213371c47f6aac5aa37f193fcd8",
            "3c6fcb7ccac54d7a804c2c095eb5ca92",
            "d3e0dbade44b4fa4a7c4fc6b7995f407",
            "4a58345179204ab3be80137877121bb3",
            "776629b4ba1a4967aec24da1f6b39db2",
            "df3bb3f7a6cd470d97399016626e54ba",
            "2706006d20584041824a85a51f6ac26e",
            "4989648ab19248169441868bae3c0dc1",
            "114ac540e1e94fed9370f2a23f629b16",
            "85235688494347a6aa1eba2a6f4347da",
            "0b2f1d204a4548b5a4d881924f943646",
            "3a61821280db471db21b6d40bd325a37",
            "440cfc6647d44c4599b8f2418c5f796d",
            "25232f9e020347418465cb783c409c99",
            "e44c1980baeb47afaf70b75aa4ea381e",
            "c031e071b6ae493d8be8f15579b2c60f",
            "fc50c09b085048e5b9873660d2c93e60",
            "279b230ad0e04a5eb30ab0ab7a0823f9",
            "693425edcd474a9ea7d2258960fb73f4",
            "98450f50c0e247b08c33cd5585d3b742",
            "70b6fd999eb044cf8be62eb263532647",
            "5c7a025859a944e580bc97fd594e983c",
            "5539bae3831045789389e18b9f3ef1e6",
            "8ce9fb4654d54ac1ada31271f8b40eb8",
            "61414e2ce7c24b6598ff0fb7cab056bc",
            "a5e00a8e00d14a8ab54ed92547956fd3",
            "c34a50f9110b4a81b7d3480836a20c16",
            "015f8b0c21874fb1acba4980e50d9d0b",
            "32f340334de84a72a905587ec3867b84",
            "1a9c90f93d9a4efebec7547ef8037f2a",
            "a0557e7b40d44d66b9d18738084bf8b8",
            "3a5849df94f64e9dabbe21734a02dd70",
            "36e450bf0e1a42efa5e4837159e30dde",
            "9e3aa1ff06284fe388316629bb5c4ff5",
            "1e4406db361842958aa2b3876b3ebf76",
            "bfe022a3e2c540a4a502de565edc840a",
            "6c4c1776e45149fd98cd936dbd6c02a3",
            "26a60b45ad974f4186e943b62b61e224",
            "0c3ab9530eb145cfbff343bc1d9bb193",
            "ab165ac65fc14147a32f3fc4d2a5aa32",
            "d08e3ebe63cd42e68f35ed12202dd34a",
            "8e2891a50ea04469b2d56b64ad5a3f1f",
            "659fa9e98a2345dcbeecf1446eb35ccc",
            "92d8e0e371454ff6905c60fbc62649d2",
            "ef991ff14696469c8087f52c11767d71",
            "1a2d672d837842c5bc8960293a5a86f3",
            "8cc7056cf9e345d68f837b73854e697a",
            "eb354c56e5e146398e25f3488463a1d7",
            "247238d901554b96bdba5b0c367919bc",
            "27ac3baca10147d3bfa5a7d09b1ceab1",
            "3c6644e272d44e2292585211734e8115",
            "c865ad02b100427b945a236dfed64b43",
            "5b9ec76eae444d1f8dce9439c35a6b33",
            "fe7014e47495464d86891f0f58771d58",
            "a1e3d45bba3b40dfb1d18d7512eb7248",
            "0f322738b19b4abfbf7cd980e1e0811d",
            "9e3e0627c96e49cfa21830cb89c4aca3",
            "577d2bfebd8848a88dca318e14e721df",
            "0672ec106ff54dccbecaae47cdc255a7",
            "bbbbe44c88ea4d42a9b3b0d54b5fec44",
            "83a14b535d694ddda95cb4abd71a89df",
            "46e82aa15a764d2485b39ceca4bde20f",
            "037c3568c10d4ef792fd9021c4865978",
            "a9cb87cad93843199dbe103f1412e242",
            "067e92174ffe43a09424b36ad2a33fba",
            "faaa9d15f043482db350ac021a993cae",
            "a05cb5db2f9746a4911bcea4c3a5d8fc",
            "609d60ca38224d0ba2497d1acfbe46d5",
            "b91c3a7f084140c9804a628d24c66181",
            "f4794221a1074db58cf5c5d6c658f004",
            "1e06e03ca00d48468fff652d1713160e",
            "dd86fce7111b4713ac088875713faaec",
            "09ee2a6749c34bffb3316ae61ba5cffe",
            "86e7e2dc9158415f9bb3e441cbc0615a",
            "22df79d924d444968043a75046767263"
          ]
        },
        "id": "dzGtivJv8KsM",
        "outputId": "d49fc9a4-3bcd-48a7-9e84-d95c9bec61e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25d6068746114c69878ae62dd7e85ed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "910c623d0cf54474a78d30ad4a1b2072"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e009d886b1b44f88139512e8c5e4f75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c426b9c027364a48b02085d3186e444f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85235688494347a6aa1eba2a6f4347da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70b6fd999eb044cf8be62eb263532647"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a5849df94f64e9dabbe21734a02dd70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "659fa9e98a2345dcbeecf1446eb35ccc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe7014e47495464d86891f0f58771d58"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "067e92174ffe43a09424b36ad2a33fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A tug-of-war rope with two opposing ends, one labeled \"baseless claims\" and the other \"facts,\" with the rope's center section featuring a graph showing fluctuating inflation rates, symbolizing the complexity of economic trends and the need for fact-based discourse.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eKyjcnbueMd_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rg2G2-UkeNJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **generating title from llaama3.2 which we later used as image generation model prompt**"
      ],
      "metadata": {
        "id": "CBBM0rRw6aZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sPSxvnQe79l",
        "outputId": "c571a149-6bc0-42bb-94c5-3b4bb4451e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.47.0\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "LGnxK-hhfEaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **using summarised input from summariser model**"
      ],
      "metadata": {
        "id": "rgM0mXp96VT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\" Former President Trump said the current inflation rate is the worst in 100 years. However, the highest inflation rate during the Biden era was 9.1% in June 2022. This peak, while significant, occurred over 40 to 41 years ago\"\"\"\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an excellent story title generator.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate a five-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claimed and actual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "7361a68af698423fad0df26392c41862",
            "9801a42f5d57441980569c8ca3e1b68c",
            "29b9b58d4be34c61abc721be0ab8a7e1",
            "92e310570e6a443d933505705cff17ee",
            "53fb90d463f344349df85c011fd997b0",
            "36761caa93ed417385ae35c213b98885",
            "9e06279d2b87418ba3c1f0751e50bd3e",
            "60a47283a2a744c7b93f3cfb198c19b5",
            "2582ecc3324a449a9531a81dd8fb2688",
            "90b1518a60604f98a9a4f8e666a977fc",
            "5363ddc9eff5472f8b53dda1ce39ac61"
          ]
        },
        "id": "0b6xC7uWfHra",
        "outputId": "f364efbf-c743-45b3-8693-9e1b8e3d64a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7361a68af698423fad0df26392c41862"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Debunking the Century's Worst Claim\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **using counter narrative as such**"
      ],
      "metadata": {
        "id": "LEzhmdGe0G57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"  In the wake of the 2008 financial crisis, the United States has witnessed a rollercoaster of economic fluctuations, with inflation rates that have both soared and subsided. The claim by former President Trump, who stated that the inflation rate was the worst in 100 years, is a misleading assertion that fails to align with historical data and economic trends.\n",
        "\n",
        "\n",
        "Contrary to Trump's assertion, the highest inflation rate recorded during the Biden presidency was 9.1% in June 2022, a figure that pales in comparison to the inflation rates of the early 1980s. This peak, while significant, occurred over 40 to 41 years ago, far from the \"100 years\" Trump referenced. Moreover, the inflation rate has since shown a marked decline, with the July 2024 rate at 3.2%, a figure that not only surpasses the Biden era's peak but also echoes rates seen in 2011.\n",
        "\n",
        "\n",
        "The flawed nature of Trump's claim is evident when examining the historical context and current economic indicators. Inflation rates have varied over the decades, influenced by numerous factors such as monetary policy, global events, and market dynamics. The assertion that the current inflation rate is the worst in a century is not only factually incorrect but also disregards the complexities of economic trends. The reality is that while inflation has been a concern, it has not reached the extremes Trump suggested, and the economy has shown resilience and adaptability in the face of challenges.\n",
        "\"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an excellent story title generator.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate a five-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claimed and actual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "7f3ebdf8187844d891f48e8cf42765c0",
            "16b8a801bd21450da98cf941443fdad4",
            "2bb5d0a5414444f2810425b509caa33e",
            "dd18714343d2458fb25df00c7ca6d359",
            "5d2f7efb77f44e488a177c728e005a1c",
            "a5a308e72d994c36ac24dcfbf7a6b15a",
            "bf94794e9123481cb12c548ce538cabd",
            "df180ccd20174c949b79c12846101667",
            "ca7791c54d4947a28cb56c339cd9b9fc",
            "40dbb9aec320496abd36795bea7ddcb4",
            "1f4ec01c1f1e4e009fc5f179d6a68aeb"
          ]
        },
        "id": "r2Ax5ky7j9Nx",
        "outputId": "88a0642c-5623-4da2-c3c8-b8142e76835b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f3ebdf8187844d891f48e8cf42765c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Debunking the Century's Worst Claim\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **asking for 8 words title as 5 word title wasnt giving corresponding image**"
      ],
      "metadata": {
        "id": "jYDczYSP0P_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"  In the wake of the 2008 financial crisis, the United States has witnessed a rollercoaster of economic fluctuations, with inflation rates that have both soared and subsided. The claim by former President Trump, who stated that the inflation rate was the worst in 100 years, is a misleading assertion that fails to align with historical data and economic trends.\n",
        "\n",
        "\n",
        "Contrary to Trump's assertion, the highest inflation rate recorded during the Biden presidency was 9.1% in June 2022, a figure that pales in comparison to the inflation rates of the early 1980s. This peak, while significant, occurred over 40 to 41 years ago, far from the \"100 years\" Trump referenced. Moreover, the inflation rate has since shown a marked decline, with the July 2024 rate at 3.2%, a figure that not only surpasses the Biden era's peak but also echoes rates seen in 2011.\n",
        "\n",
        "\n",
        "The flawed nature of Trump's claim is evident when examining the historical context and current economic indicators. Inflation rates have varied over the decades, influenced by numerous factors such as monetary policy, global events, and market dynamics. The assertion that the current inflation rate is the worst in a century is not only factually incorrect but also disregards the complexities of economic trends. The reality is that while inflation has been a concern, it has not reached the extremes Trump suggested, and the economy has shown resilience and adaptability in the face of challenges.\n",
        "\"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "66e3877fd41d471f83cd93600a8fe28b",
            "450fd2d97c354b8885f6dbf437ea906b",
            "b062164b0d334c0f82bc9daa75fe7286",
            "19dfab40d39746ea92d17f0284a9a120",
            "0f3261f4a1ad4510bf4693d736f105c1",
            "7dc82901214e41b09f3337fe4ef18017",
            "33a9eb5f1eab492d98edb9233481444c",
            "2de675bd850847afb67a08d8c01523e0",
            "66a1fffd20eb4983aa211a6ba6242928",
            "e08f17d2dc2245aa80b95d4cc27a45d2",
            "015ed19955e4406ab9bb0fbb4947fb82"
          ]
        },
        "id": "dt-6ol-Glal2",
        "outputId": "e5404e10-5836-4b7a-a75d-7cec89e7493a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66e3877fd41d471f83cd93600a8fe28b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Trump's Misleading Claim vs. Historical Economic Reality\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"The discourse surrounding the urgency of global threats has often been polarized, with former President Trump prioritizing the specter of nuclear conflict over the existential crisis of climate change. However, this stance is not only misinformed but dangerously dismissive of the scientific consensus and the immediate reality of climate change impacts.\n",
        "\n",
        "\n",
        "Contrary to Trump's assertion that the ocean's rise over the next 400 years would be negligible, NASA's data reveals a starkly different picture. The global average sea level has been rising at a rate of 0.17 inches per year in 2023, a figure that is more than double the rate Trump suggested. This acceleration is not a distant future concern but a present-day crisis, with the rate of rise between 2014 and 2023 being about 0.19 inches per year. The misleading claim that sea levels would only rise by an eighth of an inch over 400 years grossly underestimates the current pace and trajectory of sea-level rise.\n",
        "\n",
        "\n",
        "The implications of this accelerated sea-level rise are profound and far-reaching. Coastal regions, including Trump's home state of Florida, are expected to experience disproportionate effects, with rising seas threatening to inundate homes, displace communities, and devastate ecosystems. The notion that rising seas could create more oceanfront property is a dangerous fallacy that overlooks the catastrophic consequences for human settlements and natural habitats. The reality is that climate change poses an immediate and escalating threat to global security, economic stability, and the very survival of countless species, including our own. Trump's misrepresentation of the facts not only undermines informed public discourse but also hinders the urgent action required to address this global emergency.\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583,
          "referenced_widgets": [
            "de3448b8ef1d41709a3c56f7c3676abd",
            "d39ee5d0de8340158749199ca862c98a",
            "6e14589371ae4cf49d9c4e3e088a03b1",
            "12f1c5984e304c508a8284af16d21a6b",
            "af5cf58bfaeb4866a516dc498cd8ac55",
            "c75e1478c68b4dafa1bc766cf589e912",
            "289282f2cfcc41a1886a62e4fe46f81a",
            "b6b18ac8c61d47128b3f43417b9ab5e4",
            "1956b24aa9af4d8b91eb21d1c9017995",
            "1802bef7e1974adfbc3c8d2f8e162212",
            "db99ee660137416f9012bc92a20702db",
            "e525ce07a13e408583e1cc6c461f25b7",
            "009fd4864b6f471e8a9c41a72119cd19",
            "a0e52e72eab84ceda3b35638c1377edc",
            "fb7fbf157cef496ca48f56f9c188283a",
            "b98e642f7cfa4523af259d4ff5107324",
            "587509618e4c4b5f9f796f6ac2b34ded",
            "c02402fcfefc4c0a90a7e43bfb75c18f",
            "86158c6557ef47d5a51711198b083a7a",
            "50d816eb0c2a4672a6c56230c861a82b",
            "bbcb0e2a6e5e4ff799b1a21d4338e4a8",
            "385b743f41544c48898ce4a5781862bb",
            "15ead4438a17401183c40cefa634784f",
            "52b2f80254b94677b37f213d32a3744a",
            "83ef2905766a4f75b403467970e59663",
            "b1596239ddca4aa4923792d12c7b07d8",
            "a23fc93dd4494018b5ff16107632877f",
            "bab9cfea3e894f5590662bf49b69df4c",
            "37f4d3a87bdc4b14864afeb3ecbdd40b",
            "72b166ee54b4469ba83c7a2184eac483",
            "811835fd3cdb43fcaed0b4c74634ddf2",
            "bee2b454b1074232b50bc6c4dac141c5",
            "4d74909962d748d49ae96a16500ccf29",
            "6ec1f5b25a174cc2876fe1537131ef07",
            "f6b9ca63d2d24cd99e2cf2a289193e5f",
            "c9b93377059741d0a09f11b4d0b6e275",
            "6ee1787b68664c148998c67703890e9b",
            "5e4a1d494d07430e867d0902dca1d642",
            "035b8dc536d84e05bce525df97375ff0",
            "d9f8d8b118184fe687962512202b9645",
            "4992c63adc3d442c8db3cba9471baa83",
            "b6ae1c91368d426b9f9a50d58b9bdbe7",
            "ecfa59b74f8e4d739dc289d28c65fafe",
            "fb25302fbe534ce792884646a1f73517",
            "83e323b91cbc405f9802789265473e48",
            "0d46a5135b134914bd104e853d5c7a2a",
            "4725a5b93e024915aa02a6f90ee90f0a",
            "4994654118514b8cb73719b9c7a2f5bf",
            "75f6e21c23554a50bf0ff6186ad02928",
            "ae2cbb15c7b04db6a729a0c20dceebc9",
            "eb067ca6fb8a4fa6864e936c8d4173f9",
            "4d73f71a36a74f2bbd490a2346b4a852",
            "34149d842f374d5da69810131ee935ec",
            "6e460524741144ce9ae7d9d910d1bf5c",
            "926f7a53c9bf453999beefc4f984b881",
            "fdbdc049a3c744aeacf489b09ec25b11",
            "1a8351ead0b542aa97097a1a4d4e23c0",
            "4ced7a9f5a354f5a97a8aa23c2b03149",
            "a2cb8db944d34bdfae0145d6e08f519e",
            "e625a34e59734ea69739d85b54ca9f71",
            "8c08f049e4f4488d9b450ffb4a538206",
            "a5bc3a3acc9946e9aa609954440c79d4",
            "a4a436563b1c4f22a58332f6288bd0fb",
            "bf90a22cd3ff4483aaa01e37084b0777",
            "5abcc10e01b6463ab3b86e5852c0498b",
            "eded633550154748a64b522a28ba2faf",
            "9ee0c81ed68a45a98fd74a651c584728",
            "9364eae4606b40a396d12d1b6bf4c95f",
            "eb5de34a338d476799301977800c35d1",
            "7dda2f5282b84da986bfaa6a2554a7af",
            "efae997c49df4280bff7fc5d2d8f0f35",
            "df7d26a2fb9841a1b19d8ca528890110",
            "08ca3a7febeb4a9ca9b4b18814f231a9",
            "9efe2ffdc4514ab296e713c21e19e0f7",
            "5aaec631205e4d3da932644946db33e0",
            "6c52079775784b359ad882f4ce5acf0b",
            "eec676a65e27472a80303c9a02a34930",
            "5877a27d3c1c4bedb63f8c14fb0b02a7",
            "a141968a8b5848868725c3dea60184db",
            "819974808cb24fcc92d1b9ba6c24883d",
            "f5348b0d7e9a4beea20a63189108a210",
            "3c3c296f1e27460594ee6a827483a22f",
            "e5cbe42276ef4e46bed4f106f6ea38a3",
            "9bda26ece9864dacad7b18173c55a6be",
            "cc769ec9bcbf4767a6a9b19bf2ea9c83",
            "3af159b51a6a4c0188f4377045c0dd78",
            "e3fc8603e3d94b2996e96ce770930613",
            "9ed1c49fd7c643fb90564e6727b5f109",
            "ac4d260661a94ba38911abf61ea3269d",
            "2c43fec8ef30428c888eb1e22277d388",
            "286e239a50a342a29a450033b1562c4a",
            "28f1a6b21cc341458f7b09377723ee6a",
            "b2f7dc776e69450285cfd98f65053fa7",
            "8649d9a2496040eaa932a0acf31e4ee9",
            "c3a62ca3de964ebeb5938479404327f8",
            "44c88e4f3fc348f4b2aa8bc685402927",
            "1212429250e240e5a5b051c634616858",
            "2e84614c04bf476197b0e24367947f04",
            "e324d3ec18254246b5330bb9070cca4a",
            "ba907e8bbd9e47609d7f2fedcd8abb83",
            "cea9355bdc334d19b39022a41710564c",
            "e4945959a0e240cbaba620e17df2ef38",
            "e0706d8f9bc64a6e8691d65c9cd428ff",
            "c5466dd6b5b14b7a9305102315797c27",
            "3de79f27dee74a67a92eb3443f8f9207",
            "24088ebea22540d98520451ace644e48",
            "7b7afcbf81e34487b6f3f3e236b91b89",
            "9d16690a792f4d3f8b1e26c2ed0b6b19",
            "f547d948a8e94baeafe780d3d54fe8c3",
            "47643e40247847c28b0758897909477a"
          ]
        },
        "id": "yAAhI1O64WOw",
        "outputId": "374e32c2-3b90-4e59-e5e1-ffe23bd5a091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de3448b8ef1d41709a3c56f7c3676abd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e525ce07a13e408583e1cc6c461f25b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15ead4438a17401183c40cefa634784f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ec1f5b25a174cc2876fe1537131ef07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83e323b91cbc405f9802789265473e48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdbdc049a3c744aeacf489b09ec25b11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ee0c81ed68a45a98fd74a651c584728"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5877a27d3c1c4bedb63f8c14fb0b02a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac4d260661a94ba38911abf61ea3269d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba907e8bbd9e47609d7f2fedcd8abb83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Rising Tides of Deception: A Climate Crisis Unveiled\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"In the context of international relations and economic sanctions, the claim by former President Donald Trump that he compelled China to cease purchasing oil from Iran is a misleading assertion. During his presidency, the Trump administration indeed sought to curtail Iran's oil exports, a significant source of revenue for the Islamic Republic. In 2019, the administration's efforts led to a temporary decline in China's oil imports from Iran, which fell from around 800,000 barrels per day in 2018 to approximately 100,000 barrels per day by late 2019. However, this reduction was not sustained, and imports rebounded to levels between 600,000 and 700,000 barrels per day by the time Trump left office in January 2021.\n",
        "\n",
        "\n",
        "The claim that China ceased its oil purchases from Iran under Trump's leadership is factually incorrect. Industry experts, including Matt Smith from Kpler, have noted that China's reported crude imports from Iran in January 2021 were zero, but this does not reflect the reality of ongoing trade. China has been known to employ various methods to obscure its oil purchases, such as listing Iranian crude as originating from Malaysia or transferring oil to other vessels once near Malaysian waters. These tactics have allowed China to continue its oil imports from Iran despite international sanctions.\n",
        "\n",
        "\n",
        "The narrative that Trump single-handedly pressured China to stop buying Iranian oil is not only false but also overlooks the complexities of international trade and the resilience of global supply chains. The International Crisis Group's report by Ali Vaez confirms that China's oil imports from Iran increased significantly after the Trump administration's efforts. This refutation underscores the fallacy of Trump's claim and highlights the importance of understanding the nuanced dynamics of global oil markets and the limitations of unilateral sanctions in altering long-standing trade relationships.\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "9d6262f9afdd4000a4dde1a6b013ad98",
            "369928ce5a1a4d13aabd2ef19d8e1c94",
            "c70735299fec4fee83ee1beec5661021",
            "899b26f423dc4e66a7a6004d1a8bbbd3",
            "689fd65d255b417b9324171380201c22",
            "332295267e4c44b5a0edf31813b74d22",
            "103811b5558a4c95a0009bfdbb6f9d5e",
            "f0406c26e1c64e9cbaf04ec0ec2ae14b",
            "e6b5de3c7e4f4d09bcaae7a083ebf35f",
            "44ba231ee3314cadbe6a06e589e4829e",
            "74da434a2b314437a8bc4846c2eabcb7"
          ]
        },
        "id": "7aKCRk-07YcG",
        "outputId": "611329f3-73b1-41ec-b3c8-913f4fcef8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d6262f9afdd4000a4dde1a6b013ad98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Debunking Trump's False Claim on China's Oil Imports\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"In the tumultuous arena of American politics, claims of election subversion have periodically surfaced, often casting long shadows over the democratic process. The former President, Donald Trump, has been a vocal proponent of such narratives, alleging that the Biden administration orchestrated legal actions against him in various jurisdictions. These claims, however, are not only baseless but also detrimental to the integrity of the electoral system.\n",
        "\n",
        "The Manhattan case, where Trump was found guilty, is a prime example of the fallacy in Trump's assertions. Attorney General Merrick Garland's testimony to Congress clarified that the Manhattan district attorney operates independently of the federal government, including the Justice Department. This autonomy is a cornerstone of the American legal system, ensuring that local jurisdictions can enforce state laws without federal interference. Furthermore, Matthew Colangelo, the lawyer Trump repeatedly cited, was not appointed by the Biden administration but was a colleague from the New York attorney general's office before joining Bragg's office. This fact alone dismantles the notion of a coordinated effort by the Biden administration to target Trump.\n",
        "\n",
        "The reality of inflation trends and economic milestones further underscores the misleading nature of Trump's claims. Inflation, a complex economic phenomenon influenced by a myriad of factors including monetary policy, supply chain disruptions, and global events, cannot be attributed to a single administration's actions. Historical data shows that inflation rates have fluctuated over the decades, with significant periods of both high and low inflation. The current inflationary trends are a result of a confluence of global economic challenges, not the machinations of any one political entity. Trump's unfounded allegations not only misrepresent the facts but also undermine the public's understanding of economic realities. The evidence clearly refutes the claim that the Biden administration orchestrated legal actions against Trump, highlighting the importance of basing political discourse on facts rather than unfounded accusations.\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "089886e626dc428ead9102b5863a91f3",
            "9824835d1f684e9eaf4561d827900186",
            "b4b58417e78f424f8f554e77da93b469",
            "ec19360d49c84c7c97f1c0ed8f3bfdf0",
            "73dbb58aa239426f88c25ef38cdfeb41",
            "f9a69f94eab646e0a4451ee0143f33d3",
            "40c4908ab7854c1eb9db78d5bc3562f8",
            "d0032927f7674c41a46416ed8c9691df",
            "82ebfdbbc5bf466c90e0ce3fb55c80de",
            "ba5ded1eb6db4ada8e8ebeaa3449fc12",
            "9913421406b94f9a819904e19dab9559"
          ]
        },
        "id": "zGu7Kign8WiC",
        "outputId": "fc427749-215c-48a8-ba2c-102cb3d58905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "089886e626dc428ead9102b5863a91f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Debunking False Narratives in the American Electoral System\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"\n",
        "In the wake of President Trump's controversial remarks about the US military's financial contributions to Afghanistan, it's crucial to dissect the historical context and facts surrounding the US-Afghan military relationship. Since 2005, the US has invested approximately $18.6 billion in military equipment for Afghan forces, a figure that Trump misleadingly inflated to $85 billion. This misrepresentation overlooks the Defense Department's estimate that the abandoned equipment was worth only about $7.1 billion.\n",
        "\n",
        "\n",
        "The flawed narrative presented by President Trump undermines the complexity of the US-Afghan military relationship and the economic realities of war funding. By inflating the value of the equipment left behind and misrepresenting the total funding, Trump's statement fails to acknowledge the significant investment made by the US in supporting Afghan forces. The reality is that the US provided substantial military aid, but the claim of an $85 billion \"gift\" to the Taliban is a gross exaggeration that misleads the public and oversimplifies the nuanced economic and military dynamics of the conflict.\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "579c9b637c1c40b4b85b0b9f6bd98111",
            "f6f8efe3c7684c019b5939f8d99049ed",
            "4b1a0b69c8df4703a16338643c59fc15",
            "c1d3d023b2fd42fd9e6956ff6200f56b",
            "ba73d3e7e059469c808e9ad5727c788a",
            "8d53809d099c45d4977a783a39d2e8ce",
            "f3130382f6034ad8b422108bba5ce6f4",
            "7c40be77d716404796f2ca115080ae74",
            "d2af3f0649a24031b429836712b5ff57",
            "f4ed5cb6ce53412496aa15a2172f88f5",
            "82dfb7b311254ca3b741216adbc88f1d"
          ]
        },
        "id": "Eyq2SC7f2Ixw",
        "outputId": "afb46388-2972-47d1-8555-dda02f39d3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "579c9b637c1c40b4b85b0b9f6bd98111"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Trump's Misleading Figures Expose Afghan War's True Cost\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"\n",
        "  In the midst of a heated exchange between former President Donald Trump and Tesla CEO Elon Musk, Trump made a bold claim that Musk's words were being heard by an audience of \"like 60 million or something.\" This statement, made during a publicly televised event, has since been scrutinized for its accuracy.\n",
        "\n",
        "Contrary to Trump's assertion, the actual number of accounts listening to the conversation was a mere 1.1 million, as per public data on the platform where the discussion took place. Trump's figure was not only inflated but also misleading, as it conflated the number of viewers of his own post with the number of people who actively listened to the conversation. The majority of the post's viewers were likely passive observers, not engaged participants in the dialogue.\n",
        "\n",
        "The claim made by Trump not only misrepresents the scale of the audience but also undermines the credibility of his statements. It is essential to recognize that such exaggerations do not reflect the reality of the situation. Historical economic trends, such as the Great Inflation of the 1970s, demonstrate the importance of accurate data in understanding economic phenomena. Inflation, defined as the rate at which the general level of prices for goods and services is rising, and subsequently, purchasing power is falling, requires precise measurement and analysis. Trump's inflated claim about the audience size is akin to misrepresenting economic data, which can lead to misguided policies and public misperception. It is crucial to rely on factual information to make informed decisions and understand the true scope of economic and social issues.\n",
        "\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "cde3f17a5491483a88e4d49a8c3155c1",
            "3bcbeee8841f4eac9f2f3aefdcd24dc4",
            "8056f4ddc5ee419c89a32367d16132db",
            "18d99ebe4181413ba368a0c9b15c9ec5",
            "83cf6219701f4511a357dd74af9fff30",
            "3038844608c14697b4fcfc1f22a971f6",
            "cbcbc8f6445b47d09ce21e5a87977a5e",
            "e2f0ebcd33d840bcba3e86ac308d7c27",
            "9b93df30a183446687b660adb71d4c63",
            "3875a2392a8540aaacf60567a013379d",
            "e721935859c94687bdbcea089ab13b9d"
          ]
        },
        "id": "WlW6HzGw-QDQ",
        "outputId": "c695a2db-e6c3-45b1-b3f0-df2319e39d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cde3f17a5491483a88e4d49a8c3155c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Trump's Misleading Claim Exposed by Actual Numbers Revealed\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **for generating image instructions from title and summary ...outputs for generating title and summary by using laama3.2 for ist time**"
      ],
      "metadata": {
        "id": "6VHEIuzZgt-w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9vqhhe-UhguQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **generating summarised text and title from llama3.2**"
      ],
      "metadata": {
        "id": "QsE28fRe5Y7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4VBx40_x0y2",
        "outputId": "c5666550-79db-45f1-e687-7c5127a49c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.47.1\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "Ye0YGlMG5IwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\" In the wake of the 2008 financial crisis, the United States has witnessed a rollercoaster of economic fluctuations, with inflation rates that have both soared and subsided. The claim by former President Trump, who stated that the inflation rate was the worst in 100 years, is a misleading assertion that fails to align with historical data and economic trends.\n",
        "\n",
        "\n",
        "Contrary to Trump's assertion, the highest inflation rate recorded during the Biden presidency was 9.1% in June 2022, a figure that pales in comparison to the inflation rates of the early 1980s. This peak, while significant, occurred over 40 to 41 years ago, far from the \"100 years\" Trump referenced. Moreover, the inflation rate has since shown a marked decline, with the July 2024 rate at 3.2%, a figure that not only surpasses the Biden era's peak but also echoes rates seen in 2011.\n",
        "\n",
        "\n",
        "The flawed nature of Trump's claim is evident when examining the historical context and current economic indicators. Inflation rates have varied over the decades, influenced by numerous factors such as monetary policy, global events, and market dynamics. The assertion that the current inflation rate is the worst in a century is not only factually incorrect but also disregards the complexities of economic trends. The reality is that while inflation has been a concern, it has not reached the extremes Trump suggested, and the economy has shown resilience and adaptability in the face of challenges.\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are an expert in crafting compelling title and brief summary of the counte-narrative.\n",
        "        - Title (8 words max) must capture the essence of the counter-narrative.\n",
        "        - Summary (40 words max) must be brief and should effectively highlight the core aspects of the counter-narrative\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"counter-narrative: {story}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=130,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "f515ffcc45a74a648d13ae9ef90516d5",
            "2738497e32a645f6abb9c4c93cd12757",
            "74fbfb4178a0484b8d8062ec0a062a15",
            "97b7733d06f14a648cc0063c37eb1c28",
            "0c5366ed60bf4755ad32b766b31deb6b",
            "bd93fd37117540f5a21f3bbd8ad28fa8",
            "a0f2870fa9b44424ac3b6961be78af32",
            "fec113045622487499e04ccb2f835117",
            "f36a2d1b12fa40adb9de5abae8b17923",
            "cbc2869e245d470d9c5d206874126d10",
            "820a4eee9af94b6b915d557213309bfd"
          ]
        },
        "id": "Nglk8Bco5JSR",
        "outputId": "879ee4b3-41c7-4450-e3e8-26cfb55cff74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f515ffcc45a74a648d13ae9ef90516d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Title:** \"Trump's Misleading Inflation Claim: A Century Out of Context\"\n",
            "\n",
            "**Summary:** Former President Trump's claim that the US inflation rate is the worst in 100 years is a misleading assertion that fails to align with historical data and economic trends. The actual peak inflation rate during the Biden presidency was 9.1% in June 2022, far from the \"100 years\" Trump referenced, and the current rate of 3.2% is actually lower than the peak in 2011.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\" The discourse surrounding the urgency of global threats has often been polarized, with former President Trump prioritizing the specter of nuclear conflict over the existential crisis of climate change. However, this stance is not only misinformed but dangerously dismissive of the scientific consensus and the immediate reality of climate change impacts.\n",
        "\n",
        "\n",
        "Contrary to Trump's assertion that the ocean's rise over the next 400 years would be negligible, NASA's data reveals a starkly different picture. The global average sea level has been rising at a rate of 0.17 inches per year in 2023, a figure that is more than double the rate Trump suggested. This acceleration is not a distant future concern but a present-day crisis, with the rate of rise between 2014 and 2023 being about 0.19 inches per year. The misleading claim that sea levels would only rise by an eighth of an inch over 400 years grossly underestimates the current pace and trajectory of sea-level rise.\n",
        "\n",
        "\n",
        "The implications of this accelerated sea-level rise are profound and far-reaching. Coastal regions, including Trump's home state of Florida, are expected to experience disproportionate effects, with rising seas threatening to inundate homes, displace communities, and devastate ecosystems. The notion that rising seas could create more oceanfront property is a dangerous fallacy that overlooks the catastrophic consequences for human settlements and natural habitats. The reality is that climate change poses an immediate and escalating threat to global security, economic stability, and the very survival of countless species, including our own. Trump's misrepresentation of the facts not only undermines informed public discourse but also hinders the urgent action required to address this global emergency.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are an expert in crafting compelling title and brief summary of the counte-narrative.\n",
        "        - Title (8 words max) must capture the essence of the counter-narrative.\n",
        "        - Summary (40 words max) must be brief and should effectively highlight the core aspects of the counter-narrative\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"counter-narrative: {story}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=130,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "8db49afca8584bc19d0c9e0ce7fcbef8",
            "721197be02c84381a8cc38cbff0f85c7",
            "9304bea33a94481f808a7481a496134b",
            "1e6114e09b064e73a3c007f7b8535db3",
            "f3ba14eb458b4d5f9742243147c66a87",
            "ff5820a321474f08b094fe3b125bd443",
            "8d0b0a615c044d6ca970b17ee331bba5",
            "ef749138bc874109889ce12c253314e3",
            "f1c6a51219554dc99875f1dac4e3b781",
            "b5fe80c8af4b453a9cd2f5222632f260",
            "a2ec605594a54a29973f9f98ec4acc01"
          ]
        },
        "id": "j-s5BCiwYpDS",
        "outputId": "688ce4d7-35ce-4745-cc4a-966cb9e864ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8db49afca8584bc19d0c9e0ce7fcbef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Title:** \"Trump's Misguided Climate Denial: A Threat to Global Security and Survival\"\n",
            "\n",
            "**Summary:** Former President Trump's stance on climate change is misinformed and dismissive of scientific consensus, grossly underestimating the accelerated rate of sea-level rise. NASA data reveals a starkly different picture, with rising seas threatening coastal regions, displacing communities, and devastating ecosystems, posing an immediate and escalating threat to global security, economic stability, and species survival.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\" In the context of international relations and economic sanctions, the claim by former President Donald Trump that he compelled China to cease purchasing oil from Iran is a misleading assertion. During his presidency, the Trump administration indeed sought to curtail Iran's oil exports, a significant source of revenue for the Islamic Republic. In 2019, the administration's efforts led to a temporary decline in China's oil imports from Iran, which fell from around 800,000 barrels per day in 2018 to approximately 100,000 barrels per day by late 2019. However, this reduction was not sustained, and imports rebounded to levels between 600,000 and 700,000 barrels per day by the time Trump left office in January 2021.\n",
        "\n",
        "\n",
        "The claim that China ceased its oil purchases from Iran under Trump's leadership is factually incorrect. Industry experts, including Matt Smith from Kpler, have noted that China's reported crude imports from Iran in January 2021 were zero, but this does not reflect the reality of ongoing trade. China has been known to employ various methods to obscure its oil purchases, such as listing Iranian crude as originating from Malaysia or transferring oil to other vessels once near Malaysian waters. These tactics have allowed China to continue its oil imports from Iran despite international sanctions.\n",
        "\n",
        "\n",
        "The narrative that Trump single-handedly pressured China to stop buying Iranian oil is not only false but also overlooks the complexities of international trade and the resilience of global supply chains. The International Crisis Group's report by Ali Vaez confirms that China's oil imports from Iran increased significantly after the Trump administration's efforts. This refutation underscores the fallacy of Trump's claim and highlights the importance of understanding the nuanced dynamics of global oil markets and the limitations of unilateral sanctions in altering long-standing trade relationships.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are an expert in crafting compelling title and brief summary of the counte-narrative.\n",
        "        - Title (8 words max) must capture the essence of the counter-narrative.\n",
        "        - Summary (40 words max) must be brief and should effectively highlight the core aspects of the counter-narrative\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"counter-narrative: {story}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=130,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "d6594fc45f814aca82cd56c1af78fedb",
            "f6e3865d77dc488a870ca97782ae8894",
            "5b446ec0b0bd4e56a286e519d57fd8bc",
            "d17dd34946984adc9a992944052c840d",
            "6d5c905d61c74c848f55e7d5ba910517",
            "33f85d95b08d4e19a48783e8431fc31b",
            "ebb8472c986d45b5a79c5adeed4c89aa",
            "4786fdf070b240f7a2e4c3bf18edbbdd",
            "81d0ae4f2ed94fa686680c4f60651f17",
            "2d2f904637774d2e93f8cf702e8a15aa",
            "33abc494a582459bbb2a66a5f138df16"
          ]
        },
        "id": "P1wJHw7xycyV",
        "outputId": "fc49e4f3-f65f-40ec-dfad-a97566d62a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6594fc45f814aca82cd56c1af78fedb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Title:** Trump's False Claim: China's Ongoing Oil Imports from Iran Exposed\n",
            "\n",
            "**Summary:** Former President Trump falsely claimed he compelled China to cease purchasing oil from Iran. However, industry experts and reports reveal China continued its oil imports from Iran through complex methods, contradicting Trump's assertion and highlighting the limitations of unilateral sanctions in altering long-standing trade relationships.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **using llaama3.2 2nd time for getting instructions from title and summary**"
      ],
      "metadata": {
        "id": "w00zL-Tihrcu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd26848-e56b-4587-9a8f-c7812123f6d6",
        "id": "38pTCcyxipX6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.47.1\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "hg58Vuz8ipX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "t_s=\"\"\" **Title:** \"Trump's Misleading Inflation Claim: A Century Out of Context\"\n",
        "\n",
        " **Summary:** Former President Trump's claim that the US inflation rate is the worst in 100 years is a misleading assertion that fails to align with historical data and economic trends. The actual peak inflation rate during the Biden presidency was 9.1% in June 2022, far from the \"100 years\" Trump referenced, and the current rate of 3.2% is actually lower than the peak in 2011. \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"You are an excellent image instruction generator, capable of creating core elemental symbol based image corresponding to the given title and summary .\n",
        "                                         \"\"\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"- Based on the title and summary, generate clear instructions within 77 tokens for an image generation model.\n",
        "                     - The image should generate the core elemental symbol of the title and summary . For example, if the title and summary discusses inflation, the instructions might symbolically represent economic fluctuation or the impact of inflation. If the topic is global warming, the instructions should depict a relevant scene like melting ice caps or rising sea levels.\n",
        "                     - Ensure that the instructions don't ask for including any text or numerics in the image.\n",
        "                     - Refer to this title and summary of counter-narrative : {t_s}\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=100,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "f63e7d518dd84a99a3c795ffca759080",
            "0ec2a7b5f820439ba1cdb0b0b4ab4417",
            "a21cd782e07b4e07bdff02a5c5344b56",
            "2929667a5725415582b7f54c66c67377",
            "50bd8d4eadc8459cb3ab0714a98eab04",
            "0cc766872d894534b8a53236c5ec2582",
            "82ee82523e13460696ac3506b2ce51ef",
            "28ca0308523c4540a7fa76a9f8f99143",
            "0d9a4bc3a1ec4c85a00d47c6fbf04850",
            "8b3c761b4e9d40ec9d350e3093dd5e7b",
            "0408acf425c249eda69136655f990c5b"
          ]
        },
        "outputId": "be868658-61a3-44b0-f8c1-afe6d3024d83",
        "id": "RsQz3aGaipX7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f63e7d518dd84a99a3c795ffca759080"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate an image representing economic fluctuation, specifically depicting a graph with a peak at 9.1% and a current rate of 3.2%, with a red line indicating the peak during the Biden presidency and a blue line showing the current rate. Include a subtle background image of a US stock market ticker or a graph of historical inflation rates to emphasize the context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "t_s=\"\"\"**Title:** \"Trump's Misguided Climate Denial: A Threat to Global Security and Survival\"\n",
        "\n",
        "**Summary:** Former President Trump's stance on climate change is misinformed and dismissive of scientific consensus, grossly underestimating the accelerated rate of sea-level rise. NASA data reveals a starkly different picture, with rising seas threatening coastal regions, displacing communities, and devastating ecosystems, posing an immediate and escalating threat to global security, economic stability, and species survival.\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"You are an excellent image instruction generator, capable of creating core elemental symbol based image corresponding to the given title and summary .\n",
        "                                         \"\"\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"- Based on the title and summary, generate clear instructions within 77 tokens for an image generation model.\n",
        "                     - The image should generate the core elemental symbol of the title and summary . For example, if the title and summary discusses inflation, the instructions might symbolically represent economic fluctuation or the impact of inflation. If the topic is global warming, the instructions should depict a relevant scene like melting ice caps or rising sea levels.\n",
        "                     - Ensure that the instructions don't ask for including any text or numerics in the image.\n",
        "                     - Refer to this title and summary of counter-narrative : {t_s}\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "5e76cd6ed9e449149955bf8946387dc4",
            "1204bb9f6489476b88eba360fe282f15",
            "eb918f60b6764c1b84b9d907b5ba2370",
            "915b218b29e34a519bfe0d25b32401dd",
            "c1cbef2541d640f3ad83337689f252ea",
            "477d3652c4c04124af81fdf4166e6beb",
            "91ca0e88f9894f8aa1b723689644a01e",
            "afb9084e2d0d446398fa40541a2f4b74",
            "c556271d27c74f48bacddd1328eb9bac",
            "c185afc9fe664a8ab503fe2199271cda",
            "ead0eba26ef644998c70d80d02677189"
          ]
        },
        "outputId": "77f087e5-2e2b-4ef8-f7a9-3c4199ba4b87",
        "id": "Ov90Aq3YipX7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e76cd6ed9e449149955bf8946387dc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate an image representing the consequences of climate change, specifically focusing on rising sea levels and coastal displacement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "t_s=\"\"\"**Title:** Trump's False Claim: China's Ongoing Oil Imports from Iran Exposed\n",
        "\n",
        "**Summary:** Former President Trump falsely claimed he compelled China to cease purchasing oil from Iran. However, industry experts and reports reveal China continued its oil imports from Iran through complex methods, contradicting Trump's assertion and highlighting the limitations of unilateral sanctions in altering long-standing trade relationships.\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"You are an excellent image instruction generator, capable of creating core elemental symbol based image corresponding to the given title and summary .\n",
        "                                         \"\"\"\n",
        "        },\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"- Based on the title and summary, generate clear instructions within 77 tokens for an image generation model.\n",
        "                     - The image should generate the core elemental symbol of the title and summary . For example, if the title and summary discusses inflation, the instructions might symbolically represent economic fluctuation or the impact of inflation. If the topic is global warming, the instructions should depict a relevant scene like melting ice caps or rising sea levels.\n",
        "                     - Ensure that the instructions don't ask for including any text or numerics in the image.\n",
        "                     - Refer to this title and summary of counter-narrative : {t_s}\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "c98b295b58fe47949a6aeae7de1a3fb5",
            "206e30d864814491968230e7e394139c",
            "74fcbe3308944ccbb13e2d4fa5463572",
            "3ca071d93cb146eab3d6e58402f9885f",
            "e8e1475479e04a0d9cb15b2531a67c7d",
            "fb52d02823744e4e898999a36a55d212",
            "70deb43d7e0e4a6eb65e2019375dce82",
            "87858f9d9cdb4da3a1d2619ec8794b51",
            "8f0cad5bd6c649b5866eedde0d1dfa16",
            "cd236db5e9f2479ebc4fc3874cc88b5f",
            "28756eb2f5464b059ba2b860923f8799"
          ]
        },
        "outputId": "96d7eeb6-55c6-4872-f646-7e5950ee2918",
        "id": "E_bOYuQ4ipX8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c98b295b58fe47949a6aeae7de1a3fb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate an image representing the core concept of China's ongoing oil imports from Iran, symbolizing the complexity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"In the tumultuous arena of American politics, claims of election subversion have periodically surfaced, often casting long shadows over the democratic process. The former President, Donald Trump, has been a vocal proponent of such narratives, alleging that the Biden administration orchestrated legal actions against him in various jurisdictions. These claims, however, are not only baseless but also detrimental to the integrity of the electoral system.\n",
        "\n",
        "The Manhattan case, where Trump was found guilty, is a prime example of the fallacy in Trump's assertions. Attorney General Merrick Garland's testimony to Congress clarified that the Manhattan district attorney operates independently of the federal government, including the Justice Department. This autonomy is a cornerstone of the American legal system, ensuring that local jurisdictions can enforce state laws without federal interference. Furthermore, Matthew Colangelo, the lawyer Trump repeatedly cited, was not appointed by the Biden administration but was a colleague from the New York attorney general's office before joining Bragg's office. This fact alone dismantles the notion of a coordinated effort by the Biden administration to target Trump.\n",
        "\n",
        "The reality of inflation trends and economic milestones further underscores the misleading nature of Trump's claims. Inflation, a complex economic phenomenon influenced by a myriad of factors including monetary policy, supply chain disruptions, and global events, cannot be attributed to a single administration's actions. Historical data shows that inflation rates have fluctuated over the decades, with significant periods of both high and low inflation. The current inflationary trends are a result of a confluence of global economic challenges, not the machinations of any one political entity. Trump's unfounded allegations not only misrepresent the facts but also undermine the public's understanding of economic realities. The evidence clearly refutes the claim that the Biden administration orchestrated legal actions against Trump, highlighting the importance of basing political discourse on facts rather than unfounded accusations.\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "089886e626dc428ead9102b5863a91f3",
            "9824835d1f684e9eaf4561d827900186",
            "b4b58417e78f424f8f554e77da93b469",
            "ec19360d49c84c7c97f1c0ed8f3bfdf0",
            "73dbb58aa239426f88c25ef38cdfeb41",
            "f9a69f94eab646e0a4451ee0143f33d3",
            "40c4908ab7854c1eb9db78d5bc3562f8",
            "d0032927f7674c41a46416ed8c9691df",
            "82ebfdbbc5bf466c90e0ce3fb55c80de",
            "ba5ded1eb6db4ada8e8ebeaa3449fc12",
            "9913421406b94f9a819904e19dab9559"
          ]
        },
        "outputId": "fc427749-215c-48a8-ba2c-102cb3d58905",
        "id": "TDUxwnE7ipX8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "089886e626dc428ead9102b5863a91f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Debunking False Narratives in the American Electoral System\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"\n",
        "In the wake of President Trump's controversial remarks about the US military's financial contributions to Afghanistan, it's crucial to dissect the historical context and facts surrounding the US-Afghan military relationship. Since 2005, the US has invested approximately $18.6 billion in military equipment for Afghan forces, a figure that Trump misleadingly inflated to $85 billion. This misrepresentation overlooks the Defense Department's estimate that the abandoned equipment was worth only about $7.1 billion.\n",
        "\n",
        "\n",
        "The flawed narrative presented by President Trump undermines the complexity of the US-Afghan military relationship and the economic realities of war funding. By inflating the value of the equipment left behind and misrepresenting the total funding, Trump's statement fails to acknowledge the significant investment made by the US in supporting Afghan forces. The reality is that the US provided substantial military aid, but the claim of an $85 billion \"gift\" to the Taliban is a gross exaggeration that misleads the public and oversimplifies the nuanced economic and military dynamics of the conflict.\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "579c9b637c1c40b4b85b0b9f6bd98111",
            "f6f8efe3c7684c019b5939f8d99049ed",
            "4b1a0b69c8df4703a16338643c59fc15",
            "c1d3d023b2fd42fd9e6956ff6200f56b",
            "ba73d3e7e059469c808e9ad5727c788a",
            "8d53809d099c45d4977a783a39d2e8ce",
            "f3130382f6034ad8b422108bba5ce6f4",
            "7c40be77d716404796f2ca115080ae74",
            "d2af3f0649a24031b429836712b5ff57",
            "f4ed5cb6ce53412496aa15a2172f88f5",
            "82dfb7b311254ca3b741216adbc88f1d"
          ]
        },
        "outputId": "afb46388-2972-47d1-8555-dda02f39d3fc",
        "id": "zm58I-S6ipX9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "579c9b637c1c40b4b85b0b9f6bd98111"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Trump's Misleading Figures Expose Afghan War's True Cost\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "story=\"\"\"\n",
        "  In the midst of a heated exchange between former President Donald Trump and Tesla CEO Elon Musk, Trump made a bold claim that Musk's words were being heard by an audience of \"like 60 million or something.\" This statement, made during a publicly televised event, has since been scrutinized for its accuracy.\n",
        "\n",
        "Contrary to Trump's assertion, the actual number of accounts listening to the conversation was a mere 1.1 million, as per public data on the platform where the discussion took place. Trump's figure was not only inflated but also misleading, as it conflated the number of viewers of his own post with the number of people who actively listened to the conversation. The majority of the post's viewers were likely passive observers, not engaged participants in the dialogue.\n",
        "\n",
        "The claim made by Trump not only misrepresents the scale of the audience but also undermines the credibility of his statements. It is essential to recognize that such exaggerations do not reflect the reality of the situation. Historical economic trends, such as the Great Inflation of the 1970s, demonstrate the importance of accurate data in understanding economic phenomena. Inflation, defined as the rate at which the general level of prices for goods and services is rising, and subsequently, purchasing power is falling, requires precise measurement and analysis. Trump's inflated claim about the audience size is akin to misrepresenting economic data, which can lead to misguided policies and public misperception. It is crucial to rely on factual information to make informed decisions and understand the true scope of economic and social issues.\n",
        "\n",
        "\n",
        " \"\"\"\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an exceptional story title generator. Your task is to craft a concise yet descriptive title that captures the scene of the story. The title should be up to 8 words and emphasize the key contrasts and context.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Generate an up-to-8-word title for the story:\n",
        "\n",
        "Story Key Elements:\n",
        "- Highlight the contrast between claim and actual factual trends.\n",
        "\n",
        "Story Context: {story}\n",
        "\"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "outputs = pipe(\n",
        "    messages,\n",
        "    max_new_tokens=20,\n",
        "    do_sample=False,\n",
        "    temperature=0.7,\n",
        "    return_full_text=False\n",
        "\n",
        ")\n",
        "print(outputs[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "cde3f17a5491483a88e4d49a8c3155c1",
            "3bcbeee8841f4eac9f2f3aefdcd24dc4",
            "8056f4ddc5ee419c89a32367d16132db",
            "18d99ebe4181413ba368a0c9b15c9ec5",
            "83cf6219701f4511a357dd74af9fff30",
            "3038844608c14697b4fcfc1f22a971f6",
            "cbcbc8f6445b47d09ce21e5a87977a5e",
            "e2f0ebcd33d840bcba3e86ac308d7c27",
            "9b93df30a183446687b660adb71d4c63",
            "3875a2392a8540aaacf60567a013379d",
            "e721935859c94687bdbcea089ab13b9d"
          ]
        },
        "outputId": "c695a2db-e6c3-45b1-b3f0-df2319e39d94",
        "id": "NObfkwxgipX-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cde3f17a5491483a88e4d49a8c3155c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Trump's Misleading Claim Exposed by Actual Numbers Revealed\"\n"
          ]
        }
      ]
    }
  ]
}